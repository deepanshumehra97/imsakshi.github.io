<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-07-17T12:10:49+05:30</updated><id>http://localhost:4000/</id><title type="html">Thoughts of a Data Scientist</title><subtitle>Blog about my learnings in Data Science field</subtitle><entry><title type="html">Data Science Experience (DSX)</title><link href="http://localhost:4000/IBM-DataScienceExperience/" rel="alternate" type="text/html" title="Data Science Experience (DSX)" /><published>2017-11-27T00:00:00+05:30</published><updated>2017-11-27T00:00:00+05:30</updated><id>http://localhost:4000/IBM-DataScienceExperience</id><content type="html" xml:base="http://localhost:4000/IBM-DataScienceExperience/">&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/dsx.png&quot; alt=&quot;DSX&quot; /&gt;&lt;br /&gt;
At DataWorks Summit this year, two giants of IT world &lt;em&gt;IBM&lt;/em&gt; and &lt;em&gt;Hortonworks&lt;/em&gt; announced their resolve to develop a tool that would harness enormous amount of data stashed in hadoop installations across different verticals to be utilised to predict insights into it (the data).
&lt;br /&gt;
&lt;img src=&quot;http://localhost:4000/images/IBM.png&quot; alt=&quot;IBM&quot; /&gt;
&lt;img src=&quot;http://localhost:4000/images/partner.jpeg&quot; alt=&quot;&quot; /&gt;&lt;img src=&quot;http://localhost:4000/images/hw.jpeg&quot; alt=&quot;Hortonworks&quot; /&gt;
&lt;br /&gt;
Though it was not a path breaking announcement as Data Scientists (or so called Data Charmers) were paid hefty amounts for this very reason.&lt;/p&gt;

&lt;p&gt;Recently, IBM released DSX, a unified tool that addresses entire process of Data Science and Machine learning.&lt;/p&gt;

&lt;h2 id=&quot;why-dsx&quot;&gt;&lt;a href=&quot;#header-2&quot;&gt;&lt;/a&gt;Why DSX?&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;“Data is the king and Queen”&lt;/strong&gt;  was the moto of every organization from the days of Industrial revolution. Companies had preserved this asset in Datawarehouses but often a big chunk of it remained untapped due to limited processing power at their disposal.&lt;/p&gt;

&lt;p&gt;But almost a decade ago, with the advent of hadoop this has changed and now big amount of data can be processed using commodity hardware in reasonable time. 
&lt;img src=&quot;http://localhost:4000/images/hadoop.jpeg&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
Earlier, Data Scientists build models using only a subset of data to learn patterns in it (small data, small learning) but using the compute provided by hadoop they can use big data to learn more accurate patterns in it (Big Data, Big Learning).So the combination of Data Science and Big data was inevitable that is why the leader in data analytics and Science,IBM and the prominet player of big data world, Hortonworks joined hands.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“Data is the new oil”&lt;/strong&gt; is the moto of organisation(s) these days &lt;strong&gt;:):)&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;what-is-dsx-&quot;&gt;&lt;a href=&quot;#header-2&quot;&gt;&lt;/a&gt;What is DSX ?&lt;/h2&gt;

&lt;p&gt;IBM Data Science Experience is an analytics environment that includes popular tools such as Jupyter Notebook, R studio on top of spark-as-a-service. Currently, Python, R, Spark is supported but efforts are going on to include Zeppelin popular tools among analytics community.&lt;/p&gt;

&lt;p&gt;Using DSX one can abstract the complexities faced to intergate hetrogeneous tools to buid and deploy machine learning models. It has vibrant spark engine for processing the data, an object store to store computed models and seamless deployment of them from development into production.&lt;/p&gt;

&lt;p&gt;It can also be used as a collaborating tool as different devlopres working on the same project can exchage ideas and code without any pain.Also,cognitive capabilities of the platform guides an inexperienced user to learn,design,develop and deploy ML models seamlessly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cience E&lt;strong&gt;X&lt;/strong&gt;perience is offered in three variants&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;DSX Cloud&lt;/strong&gt; ,the cloud based version&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DSX Local&lt;/strong&gt; (On-premise) and&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DSX Desktop&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Developers can develop on-premise and throw their code into production in cloud i.e develop scikit or R model locally using some data and score this model on some new data in the cloud.&lt;/p&gt;

&lt;p&gt;Versioning capabilities built-in into DSX helps to put your model into continuous training loop i.e your model can adjust to the new incoming data and realign itself without hampring your end-users and performance.&lt;/p&gt;

&lt;p&gt;Data store is not locked to one vendor.One can also use AWS S3 or some other cloud offering as well as MySQL.&lt;/p&gt;

&lt;p&gt;Lot of community driven code(Jupyter Notebooks) and tutorials are also provided to master the craft of predicting.&lt;/p&gt;

&lt;h2 id=&quot;how-dsx-&quot;&gt;&lt;a href=&quot;#header-2&quot;&gt;&lt;/a&gt;How DSX ?&lt;/h2&gt;

&lt;p&gt;To learn more on DSX&lt;/p&gt;

&lt;p&gt;1.Sign in for free trail(Limited Period)of DSX &lt;a href=&quot;https://datascience.ibm.com&quot;&gt;here&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;2.Explore various tutorials and code books available at the dashboard (once you log in).&lt;/p&gt;

&lt;p&gt;Disclimer: IBM and Hortonworks are registered trademarks of their respective owners.Images used in this post is sourced from Internet.&lt;/p&gt;</content><author><name></name></author><summary type="html">At DataWorks Summit this year, two giants of IT world IBM and Hortonworks announced their resolve to develop a tool that would harness enormous amount of data stashed in hadoop installations across different verticals to be utilised to predict insights into it (the data). Though it was not a path breaking announcement as Data Scientists (or so called Data Charmers) were paid hefty amounts for this very reason. Recently, IBM released DSX, a unified tool that addresses entire process of Data Science and Machine learning.</summary></entry><entry><title type="html">Ensemble Learning Models</title><link href="http://localhost:4000/Ensemble-Models/" rel="alternate" type="text/html" title="Ensemble Learning Models" /><published>2017-11-13T00:00:00+05:30</published><updated>2017-11-13T00:00:00+05:30</updated><id>http://localhost:4000/Ensemble-Models</id><content type="html" xml:base="http://localhost:4000/Ensemble-Models/">&lt;p&gt;Ensemble Learning is a technique that combines two or more algorithms of similar or dissimilar types called Base or weak learners. In contrast to ML, Ensemble learning allows to train multiple learners at a same time to solve the  problem. Ensemble methods are an excellent way to improve predictive performance and are widely used on Kaggle platform by Data Scientists to improve accuracy and performance of their models.&lt;/p&gt;

&lt;p&gt;Random forests is an ensemble learning method that builds a large number of decision trees that are weak classifiers and then combine them to build a stable and strong classifier that is better than the individual trees created in the forest.This falls under the axiom that “whole is greater than the sum of its parts”.&lt;/p&gt;

&lt;p&gt;Some of the widely used ensemble learning techniques are&lt;/p&gt;

&lt;h1 id=&quot;bagging&quot;&gt;&lt;a href=&quot;#header-1&quot;&gt;&lt;/a&gt;Bagging&lt;/h1&gt;

&lt;p&gt;Bagging stands for &lt;strong&gt;B&lt;/strong&gt;ootstrap &lt;strong&gt;Agg&lt;/strong&gt;regat&lt;strong&gt;ing&lt;/strong&gt; which means different training subsets are randomly drawn, with replacement from  the entire training datasets.
Each training data subset is used to train a different classifier of a same type and then all the individual classifiers are combined for a final decision.&lt;/p&gt;
&lt;h1 id=&quot;boosting&quot;&gt;&lt;a href=&quot;#header-1&quot;&gt;&lt;/a&gt;Boosting&lt;/h1&gt;

&lt;p&gt;Boosting is a two step approach, in which we first uses subsets of the original data to produce a series of averagely performing models and then “boosts” their performance by combining them using a particular cost function. Unlike Bagging , subset creation is not random it depends upon the performance of previous models used.XGBoost,GBM,AdaBoost are all ensemble models.&lt;/p&gt;
&lt;h1 id=&quot;stacking&quot;&gt;&lt;a href=&quot;#header-1&quot;&gt;&lt;/a&gt;Stacking&lt;/h1&gt;

&lt;p&gt;In stacking, multiple layers of machine learning models are placed one over another where each of the model passes their predictions to the model in the layer above it and the top-layer model takes decision based on the output of the models in layers below it.&lt;/p&gt;</content><author><name></name></author><summary type="html">Ensemble Learning is a technique that combines two or more algorithms of similar or dissimilar types called Base or weak learners. In contrast to ML, Ensemble learning allows to train multiple learners at a same time to solve the problem. Ensemble methods are an excellent way to improve predictive performance and are widely used on Kaggle platform by Data Scientists to improve accuracy and performance of their models.</summary></entry></feed>